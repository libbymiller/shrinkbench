{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check we're using the correct python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shrinkbench.experiment import PruningExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DATAPATH` and `WEIGHTSPATH` environment variables are used to tell the framework where to look for datasets and pretrained weights respectively.\n",
    "\n",
    "MNIST is not in [hub](https://pytorch.org/docs/stable/hub.html). You can get pretrained models from other sources ([e.g.](https://github.com/csinva/gan-vae-pretrained-pytorch/blob/master/mnist_classifier/weights/lenet_epoch%3D12_test_acc%3D0.991.pth)), but that one doesn't work, as it's a different model.\n",
    "\n",
    "Pretrained weights might work with a different model that _is_ in hub, or you can just say `pretrained = False` when going through the strategies below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pwd = os.getcwd() \n",
    "data_path = pwd+'/../../data'\n",
    "# weights_path =  '' # for pretrained models\n",
    "\n",
    "os.environ['DATAPATH'] = data_path\n",
    "#os.environ['WEIGHTSPATH'] = weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "datasets.MNIST(data_path, train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get weird errors ifd something fails, this is to clean up if need be.\n",
    "import shutil\n",
    "shutil.rmtree('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run experiments for our MNIST network for logarithmically spaced compression ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strategy in ['RandomPruning', 'GlobalMagWeight', 'LayerMagWeight']:\n",
    "    for  c in [1,2,4,8,16,32,64]:   \n",
    "        exp = PruningExperiment(dataset='MNIST', \n",
    "                                model='MnistNet',\n",
    "                                pretrained=False,\n",
    "                                strategy=strategy,\n",
    "                                compression=c,\n",
    "                                train_kwargs={'epochs':10})\n",
    "        exp.run()\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then collect output from experiment folders and plot the different metrics easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shrinkbench.plot import df_from_results, plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from_results('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the provided functions, it is easy to generate plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df, 'compression', 'pre_acc5', markers='strategy', line='--', colors='strategy', suffix=' - pre')\n",
    "plot_df(df, 'compression', 'post_acc5', markers='strategy', fig=False, colors='strategy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the theoretical speedup and see that layerwise provides larger FLOPS speedups because of the even pruning of the conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plot_df(df, 'speedup', 'post_acc5', colors='strategy', markers='strategy')\n",
    "plt.ylim(0.5,0.999)\n",
    "plt.xticks(2**np.arange(7))\n",
    "plt.gca().set_xticklabels(map(str, 2**np.arange(7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily check if the compression is matching our expectation by looking at the relative error. As expected, random pruning does worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['compression_err'] = (df['real_compression'] - df['compression'])/df['compression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df, 'compression', 'compression_err', colors='strategy', markers='strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
